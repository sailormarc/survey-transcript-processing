{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question splitting\n",
    "\n",
    "This notebook takes folders containing full transcriptions of the interviews, and uses openai's chat completion API with a 1-shot prompting strategy to separate the full text into separate blocks for each of the (7 to 9) survey questions. \n",
    "\n",
    "The main functions for the processing are contained in the file utils.py. \n",
    "\n",
    "Outputs: \n",
    "1. Folders with one txt file for each interview, containing the LLM output (blocks separated by LLM delimiters and reasoning steps):\n",
    "    - ../../data/transcriptions_all/splits/1-shot_gpt-4o_groundtruth_round1\n",
    "    - ../../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round1\n",
    "    - ../../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round1\n",
    "2. Datasets in wide format (1 line per interview) with question text and answer for each question:\n",
    "    - ../../data/transcriptions_all/splits/1-shot_gpt-4o_groundtruth_round1.xlsx\n",
    "    - ../../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round1.xlsx\n",
    "    - ../../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round1.xlsx\n",
    "\n",
    "Note: for round 1 of the interviews, data was prepared in long format (1 line for each question), for reasons relevant at the time. The splitting function has been tailored to this shape, and at the end we reshape into wide format (1 line per interview/phone number). For round 2 we replicated this extra (unnecessary) step to be able to use the processing functions from round 1, but this should be simplified in future work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and constants for the notebook\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import utils\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utils import SYSTEM_PROMPT_SPLIT\n",
    "\n",
    "# Set directory paths\n",
    "data_dir = \"../../data\"\n",
    "transcripts_dir = os.path.join(data_dir, \"transcriptions_all\")\n",
    "qualtrics_dir = os.path.join(data_dir, \"working/qualtrics\")\n",
    "output_dir_splits = os.path.join(transcripts_dir, \"splits\")\n",
    "transcriptions_round_1_automatic = os.path.join(transcripts_dir, \"transcriptions_round1_relabeled\")\n",
    "transcriptions_round_2_automatic = os.path.join(transcripts_dir, \"transcriptions_round2_relabeled\")\n",
    "\n",
    "\n",
    "## Set input file paths\n",
    "\n",
    "transcriptions_round_1_dta_path = os.path.join(transcripts_dir, \"full_transcriptions_with_controls_11apr2024.dta\")\n",
    "transcriptions_round_1_groundtruth_path = os.path.join(transcripts_dir, \"transcriptions_all_split_11apr2024.xlsx\")\n",
    "controls_round_2_path = os.path.join(qualtrics_dir, \"qualtrics_v2_07may.dta\")\n",
    "\n",
    "# examples to use for 1-shot prompting\n",
    "examples_round_1_path = os.path.join(transcripts_dir, \"examples_wide_round1.xlsx\")\n",
    "examples_round_2_path = os.path.join(transcripts_dir, \"examples_wide_round2.xlsx\")\n",
    "\n",
    "## Set output file paths and directories\n",
    "\n",
    "output_dir_splits_round1_groundtruth = os.path.join(output_dir_splits, '1-shot_gpt-4o_groundtruth_round1')\n",
    "output_dataset_splits_round1_groundtruth = os.path.join(output_dir_splits, '1-shot_gpt-4o_groundtruth_round1.xlsx')\n",
    "\n",
    "output_dir_splits_round1_nova2 = os.path.join(output_dir_splits, '1-shot_gpt-4o_nova2_round1')\n",
    "output_dataset_splits_round1_nova2 = os.path.join(output_dir_splits, '1-shot_gpt-4o_nova2_round1.xlsx')\n",
    "\n",
    "output_dir_splits_round2_nova2 = os.path.join(output_dir_splits, '1-shot_gpt-4o_nova2_round2')\n",
    "output_dataset_splits_round2_nova2 = os.path.join(output_dir_splits, '1-shot_gpt-4o_nova2_round2.xlsx')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split round 1, ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(transcriptions_round_1_groundtruth_path)\n",
    "\n",
    "# drop if missing reference_phone\n",
    "df = df.dropna(subset=['reference_phone'])\n",
    "\n",
    "# make reference_phone into int\n",
    "df['reference_phone'] = df['reference_phone'].astype(int)\n",
    "\n",
    "# reshape dataset to wide format\n",
    "df_wide = utils.reshape_dataset(df)\n",
    "df_examples = pd.read_excel(examples_round_1_path)\n",
    "\n",
    "# generate dictionary of examples\n",
    "examples = {}\n",
    "for _, row in df_examples.iterrows():\n",
    "    if row['winner'] == 1:\n",
    "        examples['winner'] = utils.produce_example(row)\n",
    "    else:\n",
    "        examples['loser'] = utils.produce_example(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_phone</th>\n",
       "      <th>winner</th>\n",
       "      <th>full_transcription</th>\n",
       "      <th>question_id_0</th>\n",
       "      <th>question_id_1</th>\n",
       "      <th>question_id_2</th>\n",
       "      <th>question_id_3</th>\n",
       "      <th>question_id_4</th>\n",
       "      <th>question_id_5</th>\n",
       "      <th>question_id_6</th>\n",
       "      <th>...</th>\n",
       "      <th>question_answer_0</th>\n",
       "      <th>question_answer_1</th>\n",
       "      <th>question_answer_2</th>\n",
       "      <th>question_answer_3</th>\n",
       "      <th>question_answer_4</th>\n",
       "      <th>question_answer_5</th>\n",
       "      <th>question_answer_6</th>\n",
       "      <th>question_answer_7</th>\n",
       "      <th>question_answer_8</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233534645992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Audio Name: 20240213-092637_3534645992_Phoebe_...</td>\n",
       "      <td>demographics</td>\n",
       "      <td>self_intro</td>\n",
       "      <td>money_daily</td>\n",
       "      <td>financial_situation</td>\n",
       "      <td>health_general</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>suggestions</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>233534645992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233550272383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C:Hello\\nA: Hello, good afternoon. \\nC: Aftern...</td>\n",
       "      <td>demographics</td>\n",
       "      <td>self_intro</td>\n",
       "      <td>money_daily</td>\n",
       "      <td>management_learn</td>\n",
       "      <td>health_general</td>\n",
       "      <td>alcohol</td>\n",
       "      <td>suggestions</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>233550272383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>233240964575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Audio Name: -102901_3240964575_Phoebe_U2024021...</td>\n",
       "      <td>demographics</td>\n",
       "      <td>self_intro</td>\n",
       "      <td>money_daily</td>\n",
       "      <td>management_learn</td>\n",
       "      <td>health_general</td>\n",
       "      <td>happiness</td>\n",
       "      <td>suggestions</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>233240964575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>233549157270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Audio Name: 20240213-084111_3549157270_Phoebe_...</td>\n",
       "      <td>demographics</td>\n",
       "      <td>self_intro</td>\n",
       "      <td>money_daily</td>\n",
       "      <td>saving</td>\n",
       "      <td>health_general</td>\n",
       "      <td>happiness</td>\n",
       "      <td>suggestions</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>233549157270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>233247992954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Audio Name: 20240213-094656_3247992954_Phoebe_...</td>\n",
       "      <td>demographics</td>\n",
       "      <td>self_intro</td>\n",
       "      <td>money_daily</td>\n",
       "      <td>financial_situation</td>\n",
       "      <td>health_general</td>\n",
       "      <td>stress</td>\n",
       "      <td>suggestions</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>233247992954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reference_phone  winner                                 full_transcription  \\\n",
       "0     233534645992     0.0  Audio Name: 20240213-092637_3534645992_Phoebe_...   \n",
       "1     233550272383     0.0  C:Hello\\nA: Hello, good afternoon. \\nC: Aftern...   \n",
       "2     233240964575     0.0  Audio Name: -102901_3240964575_Phoebe_U2024021...   \n",
       "3     233549157270     0.0  Audio Name: 20240213-084111_3549157270_Phoebe_...   \n",
       "4     233247992954     0.0  Audio Name: 20240213-094656_3247992954_Phoebe_...   \n",
       "\n",
       "  question_id_0 question_id_1 question_id_2        question_id_3  \\\n",
       "0  demographics    self_intro   money_daily  financial_situation   \n",
       "1  demographics    self_intro   money_daily     management_learn   \n",
       "2  demographics    self_intro   money_daily     management_learn   \n",
       "3  demographics    self_intro   money_daily               saving   \n",
       "4  demographics    self_intro   money_daily  financial_situation   \n",
       "\n",
       "    question_id_4 question_id_5 question_id_6  ... question_answer_0  \\\n",
       "0  health_general       alcohol   suggestions  ...                     \n",
       "1  health_general       alcohol   suggestions  ...                     \n",
       "2  health_general     happiness   suggestions  ...                     \n",
       "3  health_general     happiness   suggestions  ...                     \n",
       "4  health_general        stress   suggestions  ...                     \n",
       "\n",
       "  question_answer_1 question_answer_2 question_answer_3 question_answer_4  \\\n",
       "0                                                                           \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "\n",
       "  question_answer_5 question_answer_6 question_answer_7 question_answer_8  \\\n",
       "0                                                                           \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "\n",
       "      file_name  \n",
       "0  233534645992  \n",
       "1  233550272383  \n",
       "2  233240964575  \n",
       "3  233549157270  \n",
       "4  233247992954  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wide.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>winner</th>\n",
       "      <th>full_transcription</th>\n",
       "      <th>step1</th>\n",
       "      <th>step2</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>question_id_0</th>\n",
       "      <th>question_id_1</th>\n",
       "      <th>question_id_2</th>\n",
       "      <th>question_id_3</th>\n",
       "      <th>...</th>\n",
       "      <th>question_text_8</th>\n",
       "      <th>question_answer_0</th>\n",
       "      <th>question_answer_1</th>\n",
       "      <th>question_answer_2</th>\n",
       "      <th>question_answer_3</th>\n",
       "      <th>question_answer_4</th>\n",
       "      <th>question_answer_5</th>\n",
       "      <th>question_answer_6</th>\n",
       "      <th>question_answer_7</th>\n",
       "      <th>question_answer_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240222-094955_3549049712_SamDe_USTAWI-all</td>\n",
       "      <td>0</td>\n",
       "      <td>Caller: Hello.\\nAgent: Good morning.\\nCaller: ...</td>\n",
       "      <td>&lt;STEP1&gt;\\nBeginning of block 1: Agent: Okay, fi...</td>\n",
       "      <td>&lt;STEP2&gt;\\nLast sentence of the preamble: Caller...</td>\n",
       "      <td>&lt;REASONING&gt;\\n1. The number of blocks detected ...</td>\n",
       "      <td>demographics</td>\n",
       "      <td>self_intro</td>\n",
       "      <td>money_daily</td>\n",
       "      <td>saving</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Caller: Hello.\\nAgent: Good morning.\\nCaller: ...</td>\n",
       "      <td>Agent: Okay, fine. That's okay. Alright. pleas...</td>\n",
       "      <td>Agent: Okay. So, we want to know about your fi...</td>\n",
       "      <td>Agent:  Oh, okay. Okay. That's fine. That's fi...</td>\n",
       "      <td>Agent: Okay. So, please, we want to talk about...</td>\n",
       "      <td>Agent: Okay. So, what are some of the things t...</td>\n",
       "      <td>Agent: Okay. Okay. All right. That's fine. So,...</td>\n",
       "      <td>Agent: Okay, alright, thank you very much for ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audio name: 20240221-145817_3559385272_Rose_US...</td>\n",
       "      <td>1</td>\n",
       "      <td>A: Hello good afternoon\\nC: Good afternoon\\nA:...</td>\n",
       "      <td>&lt;STEP1&gt;\\nBeginning of block 1: A: Okay, all ri...</td>\n",
       "      <td>&lt;STEP2&gt;\\nLast sentence of the preamble: A: Oka...</td>\n",
       "      <td>&lt;REASONING&gt;\\n1. The number of blocks detected ...</td>\n",
       "      <td>demographics</td>\n",
       "      <td>self_intro</td>\n",
       "      <td>money_daily</td>\n",
       "      <td>financial_situation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A: Hello good afternoon\\nC: Good afternoon\\nA:...</td>\n",
       "      <td>A: Okay, all right. So please, now we move to ...</td>\n",
       "      <td>A: Okay. Okay. So please, I will now ask you s...</td>\n",
       "      <td>A: Okay. Okay. So, please, how can you compare...</td>\n",
       "      <td>A: A little. Okay, understood. All right. So, ...</td>\n",
       "      <td>A: Okay. All right. So, please, if you think a...</td>\n",
       "      <td>A: Yeah. Yeah. Sorry about that.  All right. S...</td>\n",
       "      <td>C: I win three times. First one was 1,000. Sec...</td>\n",
       "      <td>A: Okay. So, please, we are done with this sur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  winner  \\\n",
       "0        20240222-094955_3549049712_SamDe_USTAWI-all       0   \n",
       "1  Audio name: 20240221-145817_3559385272_Rose_US...       1   \n",
       "\n",
       "                                  full_transcription  \\\n",
       "0  Caller: Hello.\\nAgent: Good morning.\\nCaller: ...   \n",
       "1  A: Hello good afternoon\\nC: Good afternoon\\nA:...   \n",
       "\n",
       "                                               step1  \\\n",
       "0  <STEP1>\\nBeginning of block 1: Agent: Okay, fi...   \n",
       "1  <STEP1>\\nBeginning of block 1: A: Okay, all ri...   \n",
       "\n",
       "                                               step2  \\\n",
       "0  <STEP2>\\nLast sentence of the preamble: Caller...   \n",
       "1  <STEP2>\\nLast sentence of the preamble: A: Oka...   \n",
       "\n",
       "                                           reasoning question_id_0  \\\n",
       "0  <REASONING>\\n1. The number of blocks detected ...  demographics   \n",
       "1  <REASONING>\\n1. The number of blocks detected ...  demographics   \n",
       "\n",
       "  question_id_1 question_id_2        question_id_3  ... question_text_8  \\\n",
       "0    self_intro   money_daily               saving  ...             NaN   \n",
       "1    self_intro   money_daily  financial_situation  ...             NaN   \n",
       "\n",
       "                                   question_answer_0  \\\n",
       "0  Caller: Hello.\\nAgent: Good morning.\\nCaller: ...   \n",
       "1  A: Hello good afternoon\\nC: Good afternoon\\nA:...   \n",
       "\n",
       "                                   question_answer_1  \\\n",
       "0  Agent: Okay, fine. That's okay. Alright. pleas...   \n",
       "1  A: Okay, all right. So please, now we move to ...   \n",
       "\n",
       "                                   question_answer_2  \\\n",
       "0  Agent: Okay. So, we want to know about your fi...   \n",
       "1  A: Okay. Okay. So please, I will now ask you s...   \n",
       "\n",
       "                                   question_answer_3  \\\n",
       "0  Agent:  Oh, okay. Okay. That's fine. That's fi...   \n",
       "1  A: Okay. Okay. So, please, how can you compare...   \n",
       "\n",
       "                                   question_answer_4  \\\n",
       "0  Agent: Okay. So, please, we want to talk about...   \n",
       "1  A: A little. Okay, understood. All right. So, ...   \n",
       "\n",
       "                                   question_answer_5  \\\n",
       "0  Agent: Okay. So, what are some of the things t...   \n",
       "1  A: Okay. All right. So, please, if you think a...   \n",
       "\n",
       "                                   question_answer_6  \\\n",
       "0  Agent: Okay. Okay. All right. That's fine. So,...   \n",
       "1  A: Yeah. Yeah. Sorry about that.  All right. S...   \n",
       "\n",
       "                                   question_answer_7  \\\n",
       "0  Agent: Okay, alright, thank you very much for ...   \n",
       "1  C: I win three times. First one was 1,000. Sec...   \n",
       "\n",
       "                                   question_answer_8  \n",
       "0                                                NaN  \n",
       "1  A: Okay. So, please, we are done with this sur...  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  50%|█████     | 1/2 [01:37<01:37, 97.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output saved to  ../data/transcriptions_all/splits/1-shot_gpt-4o_groundtruth_round1/split_233548065056.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 2/2 [02:42<00:00, 81.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output saved to  ../data/transcriptions_all/splits/1-shot_gpt-4o_groundtruth_round1/split_233534645992.txt\n",
      "Data saved to ../data/transcriptions_all/splits/1-shot_gpt-4o_groundtruth_round1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for development: truncate dataset to one row with winner == 0 and one row with winner == 1\n",
    "df_win = df_wide[df_wide['winner'] == 1].head(1)\n",
    "df_lose = df_wide[df_wide['winner'] == 0].head(1)\n",
    "df_wide = pd.concat([df_win, df_lose])\n",
    "\n",
    "# set output directory and file\n",
    "out_dir = output_dir_splits_round1_groundtruth\n",
    "out_file = output_dataset_splits_round1_groundtruth\n",
    "\n",
    "# split the transcriptions and save the output\n",
    "utils.process_transcriptions(df_wide, '1-shot', SYSTEM_PROMPT_SPLIT, out_dir, out_file, 'gpt-4o', examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split round 1, nova2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "90\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "## Prepare wide dataset for question splitting\n",
    "\n",
    "# Load text files\n",
    "simple_transcripts = utils.load_text_files(transcriptions_round_1_automatic)\n",
    "print(len(simple_transcripts))\n",
    "\n",
    "# Load dta data\n",
    "dta_data = pd.read_stata(transcriptions_round_1_dta_path)\n",
    "# convert reference_phone to int\n",
    "dta_data['reference_phone'] = dta_data['reference_phone'].astype(int)\n",
    "\n",
    "# Load excel data\n",
    "df_split = pd.read_excel(transcriptions_round_1_groundtruth_path) \n",
    "df_split.columns\n",
    "# drop if missing reference_phone\n",
    "df_split = df_split.dropna(subset=['reference_phone'])\n",
    "# convert reference_phone to int\n",
    "df_split['reference_phone'] = df_split['reference_phone'].astype(int)\n",
    "\n",
    "# merge on reference_phone\n",
    "df = pd.merge(df_split, simple_transcripts, how='left', on='reference_phone')\n",
    "\n",
    "# rename columns for compatibility with function utils.process_transcriptions\n",
    "df = df.rename(columns = { 'full_transcription' : 'ground_truth'})\n",
    "df = df.rename(columns = { 'transcription' : 'full_transcription'})\n",
    "\n",
    "# Create wide dataframe\n",
    "df_wide = utils.reshape_dataset(df, file_level_vars=['winner', 'ground_truth', 'full_transcription'])\n",
    "df_wide.head()\n",
    "print(len(df_wide))\n",
    "# remove rows without transcription\n",
    "df_wide = df_wide[df_wide['full_transcription'] != '']\n",
    "print(len(df_wide))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  50%|█████     | 1/2 [01:55<01:55, 115.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output saved to  ../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round1/split_233242092383.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 2/2 [02:55<00:00, 88.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output saved to  ../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round1/split_233534645992.txt\n",
      "Data saved to ../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for development: truncate dataset to one row with winner == 0 and one row with winner == 1\n",
    "df_win = df_wide[df_wide['winner'] == 1].head(1)\n",
    "df_lose = df_wide[df_wide['winner'] == 0].head(1)\n",
    "df_wide = pd.concat([df_win, df_lose])\n",
    "\n",
    "\n",
    "# set output directory and file\n",
    "out_dir = output_dir_splits_round1_nova2 \n",
    "out_file = output_dataset_splits_round1_nova2\n",
    "\n",
    "# split the transcriptions and save the output\n",
    "utils.process_transcriptions(df_wide, '1-shot', SYSTEM_PROMPT_SPLIT, out_dir, out_file, 'gpt-4o', examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split round 2, nova2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transcriptions left after cleaning: 75.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load text files into a dataframe and save as an excel file\n",
    "out_path = os.path.join(transcripts_dir, \"transcriptions_with_controls_round2_nova2.xlsx\")\n",
    "df, samples = utils.make_dataset_from_txt_and_dta(dta_path=controls_round_2_path, output_path=out_path, directory=transcriptions_round_2_automatic)\n",
    "print(f\"Number of transcriptions left after cleaning: {samples}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset for splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: define the question maps\n",
    "\n",
    "question_map_loser = {\n",
    "  0: {\"id\": \"demographics\", \"text\": \"\"},\n",
    "  1: {\"id\": \"self_intro\", \"text\": \"To begin, we would like to know you better. Can you tell me a little bit more about yourself and your family?\"},\n",
    "  2: {\"id\": \"money_daily\", \"text\": \"How do you organize and keep track of your finances from day to day? Please tell me about any specific methods and tools you might use in this process.\"},\n",
    "  # 3: Filled later based on randomizedquestionsmoney_do\n",
    "  4: {\"id\": \"health_general\", \"text\": \"How would you describe your and your family's health?\"},\n",
    "  # 5: Filled later based on randomizedquestionshealth_do\n",
    "  6: {\"id\": \"suggestions\", \"text\": \"How can we design a better and more popular lottery? Do you have any suggestions for us?\"},\n",
    "  7: {\"id\": \"conclusion\", \"text\": \"\"},\n",
    "}\n",
    "\n",
    "question_map_winner = {\n",
    "  0: {\"id\": \"demographics\", \"text\": \"\"},\n",
    "  1: {\"id\": \"self_intro\", \"text\": \"To begin, we would like to know you better. Can you tell me a little bit more about yourself and your family?\"},\n",
    "  2: {\"id\": \"money_daily\", \"text\": \"How do you organize and keep track of your finances from day to day? Please tell me about any specific methods and tools you might use in this process.\"},\n",
    "  # 3: Filled later based on randomizedquestionsmoney_do\n",
    "  4: {\"id\": \"health_general\", \"text\": \"How would you describe your and your family's health?\"},\n",
    "  # 5: Filled later based on randomizedquestionshealth_do\n",
    "  6: {\"id\": \"suggestions\", \"text\": \"How can we design a better and more popular lottery? Do you have any suggestions for us?\"},\n",
    "  7: {\"id\": \"impact\", \"text\": \"In what way has winning the raffle impacted your life? How have you spent the money, or how do you plan to spend it?\"},\n",
    "  8: {\"id\": \"regret\", \"text\": \"Is there something you regret about spending your prize money?\"},\n",
    "  9: {\"id\": \"recommendation\", \"text\": \"What advice would you have for someone who wins the same prize as yours today?\"},\n",
    "  10: {\"id\": \"conclusion\", \"text\": \"\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: prepare long dataset for splitting and save as an excel file\n",
    "data_path = out_path\n",
    "df = utils.prepare_dataset_for_split(data_path, 11, 8, question_map_loser, question_map_winner)\n",
    "df.to_excel(os.path.join(transcripts_dir, \"transcriptions_round2_nova2_forsplit.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: prepare wide dataset for splitting. \n",
    "## Note: It is inefficient to create a dataset in long format and then convert it to wide format. \n",
    "## This is how the code evolved, but should be refactored in the future.\n",
    "\n",
    "# convert variable reference_phone to integer\n",
    "df['reference_phone'] = df['reference_phone'].astype(int)\n",
    "\n",
    "# reshape dataset to wide format\n",
    "df_wide = utils.reshape_dataset(df)\n",
    "\n",
    "# generate dictionary of examples\n",
    "df_examples = pd.read_excel(examples_round_2_path)\n",
    "examples = {}\n",
    "for _, row in df_examples.iterrows():\n",
    "    if row['winner'] == 1:\n",
    "        examples['winner'] = utils.produce_example(row)\n",
    "    else:\n",
    "        examples['loser'] = utils.produce_example(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  50%|█████     | 1/2 [01:17<01:17, 77.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output saved to  ../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round2/split_233203670791.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 2/2 [02:31<00:00, 75.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output saved to  ../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round2/split_233201629308.txt\n",
      "Data saved to ../data/transcriptions_all/splits/1-shot_gpt-4o_nova2_round2.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for development: truncate dataset to one row with winner == 0 and one row with winner == 1\n",
    "df_win = df_wide[df_wide['winner'] == 1].head(1)\n",
    "df_lose = df_wide[df_wide['winner'] == 0].head(1)\n",
    "df_wide = pd.concat([df_win, df_lose])\n",
    "\n",
    "# set output directory and file\n",
    "out_dir = output_dir_splits_round2_nova2\n",
    "out_file = output_dataset_splits_round2_nova2\n",
    "\n",
    "# split the transcriptions and save the output\n",
    "utils.process_transcriptions(df_wide, '1-shot', SYSTEM_PROMPT_SPLIT, out_dir, out_file, 'gpt-4o', examples, num_questions_loser=6, num_questions_winner=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voices2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
