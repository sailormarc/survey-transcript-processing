{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "This script does the following: \n",
    "\n",
    "1. embed the interview transcriptions, split by question, from round 1 (both automatic transcription and ground truth) and round 2 (only automatic transcription, no ground truth available) using openai and voyageai embedding models. Transcriptions come with controls ( = administrative data on the clients) from previous processing.\n",
    "2. merge transcriptions and survey data (from qualtrics)\n",
    "3. concatenate round 1 and 2 and save dataset for further analysis and visualization\n",
    "4. generate dataset of full transcriptions (not split by question) embedded with voyageai model specialized for retrieval tasks\n",
    "\n",
    "Output: \n",
    "1. ../../data/transcriptions_all/transcriptions_with_controls_round1_nova2.xlsx\n",
    "2. ../../data/transcriptions_all/embeddings/embeddings_openai_split_gpt-4o_nova2_withcontrols_round1-2.pkl\n",
    "3. ../../data/transcriptions_all/embeddings/embeddings_openai_split_gpt-4turbo_groundtruth_withcontrols_round1.pkl\n",
    "4. ../../data/transcriptions_all/embeddings/embeddings_voyage_split_gpt-4o_nova2_withcontrols_round1-2.pkl\n",
    "5. ../../data/transcriptions_all/embeddings/embeddings_voyage_split_gpt-4turbo_groundtruth_withcontrols_round1.pkl\n",
    "6. ../../data/transcriptions_all/embeddings/embeddings_voyage_nova2_withcontrols_round1-2.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import utils\n",
    "import os\n",
    "\n",
    "# set directory paths\n",
    "data_dir = \"../../data\"\n",
    "transcripts_dir = os.path.join(data_dir, \"transcriptions_all\")\n",
    "split_transcript_dir = os.path.join(data_dir, \"transcriptions_all/splits\")\n",
    "qualtrics_dir = os.path.join(data_dir, \"working/qualtrics\")\n",
    "output_dir = os.path.join(data_dir, \"transcriptions_all/embeddings\") \n",
    "embeddings_dir = output_dir \n",
    "transcriptions_round1_dir = os.path.join(transcripts_dir, \"transcriptions_round1_relabeled\") # full transcripts without controls\n",
    "\n",
    "# check if output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "### set file paths\n",
    "\n",
    "# qualtrics data\n",
    "qualtrics_round1_path = os.path.join(qualtrics_dir, \"qualtrics_23mar.dta\")\n",
    "qualtrics_round2_path = os.path.join(qualtrics_dir, \"qualtrics_v2_07may.dta\")\n",
    "\n",
    "\n",
    "# full transcripts with controls\n",
    "transcriptions_round1_with_controls = os.path.join(transcripts_dir, \"transcriptions_with_controls_round1_nova2.xlsx\") # to be created below\n",
    "transcriptions_round2_with_controls = os.path.join(transcripts_dir, \"transcriptions_with_controls_round2_nova2.xlsx\") # available from previous processing step\n",
    "\n",
    "# split transcripts with controls\n",
    "split_transcripts_round1 = os.path.join(split_transcript_dir, \"1-shot_gpt-4o_nova2_round1.xlsx\")\n",
    "split_transcripts_round2 = os.path.join(split_transcript_dir, \"1-shot_gpt-4o_nova2_round2.xlsx\")\n",
    "split_transcripts_groundtruth = os.path.join(split_transcript_dir, \"1-shot_gpt-4turbo_groundtruth_round1.xlsx\")\n",
    "\n",
    "\n",
    "# output paths openai embeddings\n",
    "output_path_nova2_openai = os.path.join(output_dir, \"embeddings_openai_split_gpt-4o_nova2_withcontrols_round1-2.pkl\")\n",
    "output_path_groundtruth_openai = os.path.join(output_dir, \"embeddings_openai_split_gpt-4turbo_groundtruth_withcontrols_round1.pkl\")\n",
    "\n",
    "# output paths voyage embeddings\n",
    "# split\n",
    "output_path_nova2_voyage = os.path.join(output_dir, \"embeddings_voyage_split_gpt-4o_nova2_withcontrols_round1-2.pkl\")\n",
    "output_path_groundtruth_voyage = os.path.join(output_dir, \"embeddings_voyage_split_gpt-4turbo_groundtruth_withcontrols_round1.pkl\")\n",
    "\n",
    "# full transcriptions\n",
    "output_path_nova2_full_voyage = os.path.join(embeddings_dir, \"embeddings_voyage_nova2_withcontrols_round1-2.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets split by question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to get embeddings dataset\n",
    "\n",
    "def gen_embeddings_dataset(df, columns_to_embed, qualtrics_path, controls = ['female', 'age', 'education', 'employment', 'duration', 'total_winnings'], model_type='openai', num_questions=7):\n",
    "    # initialize empty kwargs\n",
    "    kwargs = {}\n",
    "    \n",
    "    # model selection logic\n",
    "    if model_type == 'openai':\n",
    "        embedding_function = utils.safe_compute_embeddings\n",
    "    elif model_type == 'voyage':\n",
    "        embedding_function = utils.get_embeddings_voyage \n",
    "        kwargs['input_type'] = 'classification'\n",
    "\n",
    "    else:\n",
    "        raise ValueError('model_type must be either \"openai\" or \"voyage\"')\n",
    "    \n",
    "    # generate embeddings\n",
    "    df_split_emb = embedding_function(df, columns_to_embed=columns_to_embed, **kwargs)\n",
    "    embedded_columns = [ c + '_embedding' for c in columns_to_embed]\n",
    "    df_long = utils.reshape_answers_split_long(df_split_emb, embedded_columns, num_questions=num_questions)\n",
    "    df_long = df_long.reset_index(drop = True)\n",
    "\n",
    "    qualtrics = pd.read_stata(qualtrics_path)\n",
    "    qualtrics['reference_phone'] = qualtrics['reference_phone'].astype(float).astype(int)\n",
    "\n",
    "    df_long_with_controls = pd.merge(df_long, qualtrics[['reference_phone'] + controls], on='reference_phone', how='left')\n",
    "    print(\"Number of rows in the dataset: \", len(df_long))\n",
    "    return df_long_with_controls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding question_answer_1_gpt-4o: 100%|██████████| 58/58 [00:18<00:00,  3.10it/s]\n",
      "Embedding question_answer_2_gpt-4o: 100%|██████████| 58/58 [00:20<00:00,  2.79it/s]\n",
      "Embedding question_answer_3_gpt-4o: 100%|██████████| 58/58 [00:17<00:00,  3.36it/s]\n",
      "Embedding question_answer_4_gpt-4o: 100%|██████████| 58/58 [00:16<00:00,  3.44it/s]\n",
      "Embedding question_answer_5_gpt-4o: 100%|██████████| 58/58 [00:18<00:00,  3.20it/s]\n",
      "Embedding question_answer_6_gpt-4o: 100%|██████████| 58/58 [00:16<00:00,  3.58it/s]\n",
      "Embedding question_answer_7_gpt-4o: 100%|██████████| 58/58 [00:03<00:00, 15.96it/s] \n",
      "/Users/marcocaporaletti/anaconda3/envs/voices2024/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset:  328\n",
      "Embedding column question_answer_1_gpt-4o. Total documents: 58\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 11354\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 10373\n",
      "Embedding column question_answer_2_gpt-4o. Total documents: 58\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 12601\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 8666\n",
      "Embedding column question_answer_3_gpt-4o. Total documents: 58\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 8455\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 5706\n",
      "Embedding column question_answer_4_gpt-4o. Total documents: 58\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 9349\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 6471\n",
      "Embedding column question_answer_5_gpt-4o. Total documents: 58\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 7229\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 5232\n",
      "Embedding column question_answer_6_gpt-4o. Total documents: 58\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 10000\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 8208\n",
      "Embedding column question_answer_7_gpt-4o. Total documents: 58\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 224\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 3475\n",
      "Number of rows in the dataset:  371\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "df_split = pd.read_excel(split_transcripts_round1)\n",
    "\n",
    "# initialize list of columns to embed\n",
    "columns_to_embed = [f\"question_answer_{i+1}_gpt-4o\" for i in range(7)]\n",
    "df_split['winner_label'] = 'non-winner'\n",
    "df_split.loc[df_split['winner'] == 1, 'winner_label'] = 'winner'\n",
    "\n",
    "# embed with openai\n",
    "df_long_round1_with_controls_openai = gen_embeddings_dataset(df_split, columns_to_embed, qualtrics_round1_path, model_type='openai')\n",
    "# rename total_winnings to amount_won\n",
    "df_long_round1_with_controls_openai = df_long_round1_with_controls_openai.rename(columns = {'total_winnings':'amount_won'})\n",
    "\n",
    "# embed with voyage\n",
    "df_long_round1_with_controls_voyage = gen_embeddings_dataset(df_split, columns_to_embed, qualtrics_round1_path, model_type='voyage')\n",
    "# rename total_winnings to amount_won\n",
    "df_long_round1_with_controls_voyage = df_long_round1_with_controls_voyage.rename(columns = {'total_winnings':'amount_won'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding question_answer_1_gpt-4o: 100%|██████████| 75/75 [00:23<00:00,  3.16it/s]\n",
      "Embedding question_answer_2_gpt-4o: 100%|██████████| 75/75 [00:22<00:00,  3.29it/s]\n",
      "Embedding question_answer_3_gpt-4o: 100%|██████████| 75/75 [00:24<00:00,  3.03it/s]\n",
      "Embedding question_answer_4_gpt-4o: 100%|██████████| 75/75 [00:23<00:00,  3.25it/s]\n",
      "Embedding question_answer_5_gpt-4o: 100%|██████████| 75/75 [00:24<00:00,  3.01it/s]\n",
      "Embedding question_answer_6_gpt-4o: 100%|██████████| 75/75 [00:24<00:00,  3.09it/s]\n",
      "Embedding question_answer_7_gpt-4o: 100%|██████████| 75/75 [00:11<00:00,  6.78it/s]\n",
      "Embedding question_answer_8_gpt-4o: 100%|██████████| 75/75 [00:08<00:00,  8.79it/s] \n",
      "Embedding question_answer_9_gpt-4o: 100%|██████████| 75/75 [00:10<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset:  489\n",
      "Embedding column question_answer_1_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 12270\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 11899\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 4290\n",
      "Embedding column question_answer_2_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 10524\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 10561\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 2556\n",
      "Embedding column question_answer_3_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 6583\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 5414\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 1593\n",
      "Embedding column question_answer_4_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 9393\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 8084\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 3312\n",
      "Embedding column question_answer_5_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 6430\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 5316\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 2292\n",
      "Embedding column question_answer_6_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 9746\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 7795\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 2324\n",
      "Embedding column question_answer_7_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 236\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 4203\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 2570\n",
      "Embedding column question_answer_8_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 224\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 3018\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 1564\n",
      "Embedding column question_answer_9_gpt-4o. Total documents: 75\n",
      "Embedding documents 0 to 32\n",
      "Total tokens: 224\n",
      "Embedding documents 32 to 64\n",
      "Total tokens: 3564\n",
      "Embedding documents 64 to 96\n",
      "Total tokens: 2096\n",
      "Number of rows in the dataset:  612\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file\n",
    "df_split = pd.read_excel(split_transcripts_round2)\n",
    "\n",
    "# initialize list of columns to embed\n",
    "columns_to_embed = [f\"question_answer_{i+1}_gpt-4o\" for i in range(9)]\n",
    "df_split['winner_label'] = 'non-winner'\n",
    "df_split.loc[df_split['winner'] == 1, 'winner_label'] = 'winner'\n",
    "\n",
    "# embed with openai\n",
    "df_long_round2_with_controls_openai = gen_embeddings_dataset(df_split, columns_to_embed, qualtrics_round2_path, controls =  ['female', 'age', 'education', 'employment', 'duration', 'amount_won'], model_type='openai', num_questions=9)\n",
    "\n",
    "# embed with voyage\n",
    "df_long_round2_with_controls_voyage = gen_embeddings_dataset(df_split, columns_to_embed, qualtrics_round2_path, controls =  ['female', 'age', 'education', 'employment', 'duration', 'amount_won'], model_type='voyage', num_questions=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add round variable to both dataframes\n",
    "df_long_round1_with_controls_openai['round'] = 1\n",
    "df_long_round2_with_controls_openai['round'] = 2\n",
    "df_long_round1_with_controls_voyage['round'] = 1\n",
    "df_long_round2_with_controls_voyage['round'] = 2\n",
    "\n",
    "# merge the two dataframes\n",
    "df_long_openai = pd.concat([df_long_round1_with_controls_openai, df_long_round2_with_controls_openai])\n",
    "df_long_openai = df_long_openai.reset_index(drop = True)\n",
    "df_long_voyage = pd.concat([df_long_round1_with_controls_voyage, df_long_round2_with_controls_voyage])\n",
    "df_long_voyage = df_long_voyage.reset_index(drop = True)\n",
    "\n",
    "# add winner_label times round\n",
    "df_long_openai['winner_round'] = df_long_openai['winner_label'] + '_round' + df_long_openai['round'].astype(str)\n",
    "df_long_voyage['winner_round'] = df_long_voyage['winner_label'] + '_round' + df_long_voyage['round'].astype(str)\n",
    "\n",
    "df_long_openai.drop(columns = \"reference_phone\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_voyage.drop(columns = \"reference_phone\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final dataframes\n",
    "df_long_openai.to_pickle(output_path_nova2_openai)\n",
    "df_long_voyage.to_pickle(output_path_nova2_voyage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for ground truth (round 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "df_split = pd.read_excel(split_transcripts_groundtruth)\n",
    "\n",
    "# initialize list of columns to embed\n",
    "columns_to_embed = [f\"question_answer_{i+1}_gpt-4-turbo-2024-04-09\" for i in range(7)]\n",
    "df_split['winner_label'] = 'non-winner'\n",
    "df_split.loc[df_split['winner'] == 1, 'winner_label'] = 'winner'\n",
    "\n",
    "\n",
    "# embed with openai\n",
    "df_long_round1_groundtruth_with_controls_openai = gen_embeddings_dataset(df_split, columns_to_embed, qualtrics_round1_path, model_type='openai')\n",
    "# rename total_winnings to amount_won\n",
    "df_long_round1_groundtruth_with_controls_openai = df_long_round1_with_controls_openai.rename(columns = {'total_winnings':'amount_won'})\n",
    "\n",
    "# embed with voyage\n",
    "df_long_round1_groundtruth_with_controls_voyage = gen_embeddings_dataset(df_split, columns_to_embed, qualtrics_round1_path, model_type='voyage')\n",
    "# rename total_winnings to amount_won\n",
    "df_long_round1_groundtruth_with_controls_voyage = df_long_round1_with_controls_voyage.rename(columns = {'total_winnings':'amount_won'})\n",
    "\n",
    "# check heads\n",
    "df_long_round1_groundtruth_with_controls_openai.drop(columns = \"reference_phone\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_round1_groundtruth_with_controls_voyage.drop(columns = \"reference_phone\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index of the dataframes\n",
    "df_long_round1_groundtruth_with_controls_openai = df_long_round1_groundtruth_with_controls_openai.reset_index(drop = True)\n",
    "df_long_round1_groundtruth_with_controls_voyage = df_long_round1_groundtruth_with_controls_voyage.reset_index(drop = True)\n",
    "\n",
    "# save the dataframes\n",
    "df_long_round1_groundtruth_with_controls_openai.to_pickle(output_path_groundtruth_openai)\n",
    "df_long_round1_groundtruth_with_controls_voyage.to_pickle(output_path_groundtruth_voyage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset of full transcription embeddings for retrieval (voyage model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = transcriptions_round1_with_controls\n",
    "df_round1, samples_round1 = utils.make_dataset_from_txt_and_dta(dta_path=qualtrics_round1_path, output_path=out_path, directory=transcriptions_round1_dir)\n",
    "print(f\"Number of transcriptions left after cleaning: {samples_round1}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb_round1 = utils.get_embeddings_voyage(df_round1, columns_to_embed=[\"transcription\"], batch_size=32, input_type=\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_round2 = pd.read_excel(transcriptions_round2_with_controls)\n",
    "df_emb_round2 = utils.get_embeddings_voyage(df_round2, columns_to_embed=[\"transcription\"], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add round variable to both dataframes\n",
    "df_emb_round1['round'] = 1\n",
    "df_emb_round2['round'] = 2\n",
    "\n",
    "# merge the two dataframes\n",
    "df_emb_all = pd.concat([df_emb_round1, df_emb_round2], ignore_index = True)\n",
    "df_emb_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# save the final dataframe\n",
    "out_path = output_path_nova2_full_voyage\n",
    "df_emb_all.to_pickle(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voices2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
